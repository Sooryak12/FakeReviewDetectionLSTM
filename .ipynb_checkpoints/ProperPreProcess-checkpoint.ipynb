{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "cXKUVsdWkvR-",
    "outputId": "a24da26f-1289-4892-e529-0a244bd9f34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Using cached contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Using cached textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Using cached pyahocorasick-1.4.0.tar.gz (312 kB)\n",
      "Collecting Unidecode\n",
      "  Using cached Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyahocorasick\n",
      "Failed to build pyahocorasick\n",
      "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
      "    Running setup.py install for pyahocorasick: started\n",
      "    Running setup.py install for pyahocorasick: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\soory\\.conda\\envs\\tf\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\soory\\AppData\\Local\\Temp\\pip-wheel-t3mhi7gx'\n",
      "       cwd: C:\\Users\\soory\\AppData\\Local\\Temp\\pip-install-8j58h2k0\\pyahocorasick\\\n",
      "  Complete output (5 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'ahocorasick' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyahocorasick\n",
      "DEPRECATION: Could not build wheels for pyahocorasick which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\soory\\.conda\\envs\\tf\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\soory\\AppData\\Local\\Temp\\pip-record-i_upswhh\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\soory\\.conda\\envs\\tf\\Include\\pyahocorasick'\n",
      "         cwd: C:\\Users\\soory\\AppData\\Local\\Temp\\pip-install-8j58h2k0\\pyahocorasick\\\n",
      "    Complete output (5 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    building 'ahocorasick' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\soory\\.conda\\envs\\tf\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\soory\\\\AppData\\\\Local\\\\Temp\\\\pip-install-8j58h2k0\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\soory\\AppData\\Local\\Temp\\pip-record-i_upswhh\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\soory\\.conda\\envs\\tf\\Include\\pyahocorasick' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "wgMveFfmk-r1",
    "outputId": "5a8424ca-8294-4962-d0fa-4ec0e1f2debb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>__label1__</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  ...                                        REVIEW_TEXT\n",
       "0       1  ...  When least you think so, this product will sav...\n",
       "1       2  ...  Lithium batteries are something new introduced...\n",
       "2       3  ...  I purchased this swing for my baby. She is 6 m...\n",
       "3       4  ...  I was looking for an inexpensive desk calcolat...\n",
       "4       5  ...  I only use it twice a week and the results are...\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/Sooryak12/FakeReviewDetectionLSTM/master/selected.txt\"\n",
    "df=pd.read_csv(url,delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "819aWQjGlCDD"
   },
   "outputs": [],
   "source": [
    "df[\"LABEL\"]=df[\"LABEL\"].replace(['__label2__','__label1__'],['0','1'])\n",
    "df[\"LABEL\"]=df[\"LABEL\"].astype(np.float32)\n",
    "dfs=df[[\"REVIEW_TEXT\",\"LABEL\",\"PRODUCT_CATEGORY\"]]\n",
    "dfs = dfs.rename(columns={'REVIEW_TEXT': 'reviews',\"LABEL\":\"label\",\"PRODUCT_CATEGORY\":\"cat\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1pWjqKblKyA"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "import contractions\n",
    "def contract(text):\n",
    "  return(contractions.fix(text))\n",
    "from nlppreprocess import NLP\n",
    "NLP=NLP\n",
    "obj=NLP(remove_stopwords=True,remove_numbers=True,replace_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8WdSxqYlZa9"
   },
   "outputs": [],
   "source": [
    "dfs[\"reviews\"]=dfs[\"reviews\"].str.lower()\n",
    "dfs[\"reviews\"]=dfs[\"reviews\"].apply(contract)\n",
    "dfs[\"reviews\"]=dfs[\"reviews\"].apply(preprocess_text)\n",
    "dfs[\"reviews\"]=dfs[\"reviews\"].apply(remove_tags)\n",
    "dfs[\"reviews\"]=dfs[\"reviews\"].apply(obj.process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9GreCkJql89E"
   },
   "outputs": [],
   "source": [
    "dfs[\"len_review\"]=dfs[\"reviews\"].apply(lambda x :len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "idyMoPtZmG4o",
    "outputId": "b51c4cc6-5f2e-42af-bee1-718eb65ec3a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in dfs[\"len_review\"]:\n",
    "    if 100<i:\n",
    "      c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "AxdWnY9Dm0WA",
    "outputId": "98556011-a55c-4f73-ec6c-169ed84fc267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21000 entries, 0 to 20999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   reviews     21000 non-null  object \n",
      " 1   label       21000 non-null  float32\n",
      " 2   cat         21000 non-null  object \n",
      " 3   len_review  21000 non-null  int64  \n",
      "dtypes: float32(1), int64(1), object(2)\n",
      "memory usage: 574.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NkwOB1GsmEQQ"
   },
   "outputs": [],
   "source": [
    "dfse=dfs[dfs[\"len_review\"]<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Om49arTsm_Nj"
   },
   "outputs": [],
   "source": [
    "dfse.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "_uSh2UrToRew",
    "outputId": "90cf3e98-7bed-4600-ec0c-f3b9a8f9a4c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfse[\"label\"]=dfse[\"label\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "eNl-epqtoURG",
    "outputId": "0b900861-dcc2-4873-ce7f-ef954f91f71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19243 entries, 0 to 19242\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   reviews     19243 non-null  object\n",
      " 1   label       19243 non-null  int64 \n",
      " 2   cat         19243 non-null  object\n",
      " 3   len_review  19243 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 601.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cqo3SjKuzXD4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crEwQgjwnawo"
   },
   "outputs": [],
   "source": [
    "                                                                    ##PREPROCESSING DONE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "W2gJUZBFEXrq",
    "outputId": "d0b88fcc-6d00-44ad-fcfb-9dd2ec63c0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 28.5MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 20kB 5.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 30kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 40kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 51kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 61kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 71kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 81kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 92kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 102kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 112kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 122kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 133kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 143kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 153kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 163kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 174kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 184kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 194kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 204kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 215kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 225kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 235kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 245kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 256kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 266kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 276kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 286kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 296kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 307kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 317kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 327kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 337kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 348kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 358kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 368kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 378kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 389kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 399kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 409kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 419kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 430kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 440kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 450kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 460kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 471kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 481kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 491kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 501kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 512kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 522kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 532kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 542kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 552kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 563kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 573kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 583kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 593kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 604kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 614kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 624kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 634kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 645kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 655kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 665kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 675kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 686kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 696kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 706kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 716kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 727kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 737kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 747kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 757kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 768kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 778kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 788kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 798kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 808kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 819kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 829kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 839kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 849kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 860kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 870kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 880kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 890kB 8.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 28.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 52.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 54.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=83024116e85f4fe368bf9076bb615bd30ead783bbc9abdb42ba631bd4334d1cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bBvIgyrfB4v3",
    "outputId": "7f90ed7d-6593-4d21-bd7d-947ac9cd8011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd2c42006d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti1UCn-RCmo5"
   },
   "outputs": [],
   "source": [
    "##Another method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4kqBSnPCqV4"
   },
   "outputs": [],
   "source": [
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "RD2i73d_FABX",
    "outputId": "79c15aad-7d5a-464f-baed-95a0f68f420e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dec47279099b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \"\"\"\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m                     \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m                     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_files_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m                 )\n\u001b[1;32m   1533\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: Model name 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). We assumed 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1' was a path, a model identifier, or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url."
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqV4NUHdFMEN"
   },
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "  def __init__(self, reviews, targets, tokenizer, max_len=100):\n",
    "    self.reviews = reviews\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_l\n",
    "  def __len__(self):\n",
    "    return len(self.reviews)\n",
    "  def __getitem__(self, item):\n",
    "    review = str(self.reviews[item])\n",
    "    target = self.targets[item]\n",
    "    encoding = tokenizer.encode_plus(\n",
    "      review,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding=max_len,\n",
    "      truncation=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    return {\n",
    "      'review_text': review,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "2Ptgr4lAGYtP",
    "outputId": "44ee4f0b-54ed-4821-bac4-d0e96848e682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n",
      "\r",
      "\u001b[K     |████████                        | 10kB 24.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 20kB 6.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 30kB 7.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 40kB 3.8MB/s \n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=7a46d0f7feb16e85cfdb0b897928ed6dfb05eab2c5b4f13db1ca86b6852ce242\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=ae7bbcc4664cb82580cc2f32ea714df3f8c2699cdcf4a8233392f08a7e1ed7b6\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=986e74ecf558fbc745b29db4239a0a48f2bf79f105d9ca8fae13f0b1e965bd35\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fnz6ouN5GvqV"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8jQeXJAIIbC"
   },
   "outputs": [],
   "source": [
    "dfe = pd.DataFrame( columns=[\"reviews\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1KpnoFCHxN2"
   },
   "outputs": [],
   "source": [
    "dfe[[\"reviews\",\"label\"]]=dfse[[\"reviews\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CQ68GECHFPo"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "  dfe,\n",
    "  test_size=0.2,\n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JPNVZ7GIjRU"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = GPReviewDataset(\n",
    "    reviews=dfe.reviews.to_numpy(),\n",
    "    targets=dfe.label.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4\n",
    "  )\n",
    "BATCH_SIZE = 32\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, 100, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, 100, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "9ba80b0560ae4530938fc8322cb48479",
      "61cf0b45257c408eb68a81dad7fbbc94",
      "a1a03bcfe81c4326b45ca692bf429c51",
      "4c34d6afe2dc49e7981848ecdb6aa67c",
      "124966dae2b04459a12a8f30208a66dd",
      "457f3a3d9ca2454cbafb010919e09ece",
      "52419aa0ce9340ada4289f0a70726842",
      "39d850aba9264859b99b866e183b3ec8",
      "0795f800878d4110ac37da44b0683d6d",
      "d58675463c8d4ffcb3b78c3f20f4d21e",
      "026baa4eb1f04bf48b3d1cef6b01f8cc",
      "ba9f4252fb43414ba0ae05cdca4c2bd9",
      "d8e8a30e120a473ab5288a99f8335636",
      "c56b8cbbacd1495d8cef36f713faaf96",
      "fd7b8076750145aa9b5d8b48224b97b5",
      "b040f852fa9a42cebcf24cf0b5ef94df"
     ]
    },
    "colab_type": "code",
    "id": "w_DZd-BAI52Y",
    "outputId": "c4696d90-02c1-4668-f115-ff18962ccc38"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba80b0560ae4530938fc8322cb48479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0795f800878d4110ac37da44b0683d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9ZCHoeAJyVD"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME=\"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Bda_0-jJEiy"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    self.drop = nn.Dropout(p=0.3)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "    output = self.drop(pooled_output)\n",
    "    return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMyQpHYnJjHQ"
   },
   "outputs": [],
   "source": [
    "model = SentimentClassifier(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39-705X7JFM-"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-13o_k_JO5D"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model,\n",
    "  data_loader,\n",
    "  loss_fn,\n",
    "  optimizer,\n",
    "  scheduler,\n",
    "  n_examples\n",
    "):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"]\n",
    "    attention_mask = d[\"attention_mask\"]\n",
    "    targets = d[\"targets\"]\n",
    "    outputs = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aB30nnSJPzc"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"]\n",
    "      attention_mask = d[\"attention_mask\"]\n",
    "      targets = d[\"targets\"]\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "tHsM72zFKZzO",
    "outputId": "dc656021-ef57-4d9f-dc5e-144ecaa32773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f2f1e928c5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     len(df_train) )\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train loss {train_loss} accuracy {train_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   val_acc, val_loss = eval_model(\n",
      "\u001b[0;32m<ipython-input-93-1b3f19abf86b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-85-3b32c1091064>\", line 17, in __getitem__\n    padding=max_len,\nNameError: name 'max_len' is not defined\n"
     ]
    }
   ],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    len(df_train) )\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    len(df_test)\n",
    "  )\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIcFWtPHoHcb"
   },
   "outputs": [],
   "source": [
    "# 1 Using Bert Embeddings and ANN  link:https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b\n",
    "!wget -q https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget -q https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
    "!wget -q https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
    "!wget -q https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2sK3GEVJDdS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alqr2Wk3zzGY"
   },
   "outputs": [],
   "source": [
    "from tokenization import FullTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "!pip install -q tensorflow-hub\n",
    "!pip install -q tensorflow-datasets\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wq19tAlFsuUD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Ytrain,Ytest = train_test_split(dfse[\"reviews\"],dfse[\"label\"], test_size=0.2, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIiB_dTTsRet"
   },
   "outputs": [],
   "source": [
    "max_seq_length=100\n",
    "sess =  tf.compat.v1.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtuyCJVntVUR"
   },
   "outputs": [],
   "source": [
    "train_text = X_train.tolist()\n",
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "train_label = Ytrain.tolist()\n",
    "\n",
    "test_text = X_test.tolist()\n",
    "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = Ytest.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUZK08J0vAD2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQOuA9ItygZp"
   },
   "outputs": [],
   "source": [
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-Jv6wkk1bw7"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "4nhoyxgbt6Ej",
    "outputId": "0c6aed05-52a0-4741-a044-a5b4d16b08a7"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-169a8724fefd>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True,\"default value\")\u001b[0m\n\u001b[0m                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "class PaddingInputExample(object): \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def create_tokenizer_from_hub_module(tf_hub):\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.load(tf_hub)\n",
    "    bert_module.signatures['default'](['tokenization_info'])\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True,\"default value\")\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "    \n",
    "    #print(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "eaUNFyTF3E4V",
    "outputId": "dc017a41-7bff-47fa-99c6-7388f53b916d"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-fb8ae3323849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tokenizer_from_hub_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert data to InputExample format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_text_to_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_text_to_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-64f2560651d5>\u001b[0m in \u001b[0;36mcreate_tokenizer_from_hub_module\u001b[0;34m(tf_hub)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;34m\"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mbert_module\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_hub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mbert_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenization_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mtokenization_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokenization_info\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     vocab_file, do_lower_case = sess.run(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'default'"
     ]
    }
   ],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module(bert_path)\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_label)\n",
    "test_examples = convert_text_to_examples(test_text, test_label)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9D_aa0l2n3D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ProperPreProcess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "026baa4eb1f04bf48b3d1cef6b01f8cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c56b8cbbacd1495d8cef36f713faaf96",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8e8a30e120a473ab5288a99f8335636",
      "value": 440473133
     }
    },
    "0795f800878d4110ac37da44b0683d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_026baa4eb1f04bf48b3d1cef6b01f8cc",
       "IPY_MODEL_ba9f4252fb43414ba0ae05cdca4c2bd9"
      ],
      "layout": "IPY_MODEL_d58675463c8d4ffcb3b78c3f20f4d21e"
     }
    },
    "124966dae2b04459a12a8f30208a66dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "39d850aba9264859b99b866e183b3ec8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "457f3a3d9ca2454cbafb010919e09ece": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c34d6afe2dc49e7981848ecdb6aa67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39d850aba9264859b99b866e183b3ec8",
      "placeholder": "​",
      "style": "IPY_MODEL_52419aa0ce9340ada4289f0a70726842",
      "value": " 433/433 [00:00&lt;00:00, 3.65kB/s]"
     }
    },
    "52419aa0ce9340ada4289f0a70726842": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "61cf0b45257c408eb68a81dad7fbbc94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ba80b0560ae4530938fc8322cb48479": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1a03bcfe81c4326b45ca692bf429c51",
       "IPY_MODEL_4c34d6afe2dc49e7981848ecdb6aa67c"
      ],
      "layout": "IPY_MODEL_61cf0b45257c408eb68a81dad7fbbc94"
     }
    },
    "a1a03bcfe81c4326b45ca692bf429c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_457f3a3d9ca2454cbafb010919e09ece",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_124966dae2b04459a12a8f30208a66dd",
      "value": 433
     }
    },
    "b040f852fa9a42cebcf24cf0b5ef94df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba9f4252fb43414ba0ae05cdca4c2bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b040f852fa9a42cebcf24cf0b5ef94df",
      "placeholder": "​",
      "style": "IPY_MODEL_fd7b8076750145aa9b5d8b48224b97b5",
      "value": " 440M/440M [01:51&lt;00:00, 3.95MB/s]"
     }
    },
    "c56b8cbbacd1495d8cef36f713faaf96": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d58675463c8d4ffcb3b78c3f20f4d21e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8e8a30e120a473ab5288a99f8335636": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fd7b8076750145aa9b5d8b48224b97b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
